---
title: '[R] German Academic Twitter, Pt. 1: Mining #dvpw18, #dgs18, #hist18, #informatik2018 et al.'
author: Ilja / fubits
date: '2018-09-28'
categories:
  - Data Mining
  - Rstats
tags:
  - rtweet
  - Twitter
slug: r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al
output:
  blogdown::html_page:
    number_sections: yes
    toc: yes
lastmod: '2018-09-28T20:17:07+02:00'
description: In September, four big academic societies in Germany had their annual meeting - all at the same time! You can **not not** harvest their tweets...
thumbnail: /img/thumbs/conference_tweets.jpg
rmdlink: TRUE # Optional
comment: no
autoCollapseToc: no
postMetaInFooter: no
hiddenFromHomePage: no
contentCopyright: no
reward: no
mathjax: no
mathjaxEnableSingleDollar: no
mathjaxEnableAutoNumber: no
hideHeaderAndFooter: no
flowchartDiagrams:
  enable: no
  options: ''
sequenceDiagrams:
  enable: no
  options: ''
---


<div id="TOC">
<ul>
<li><a href="#preparation"><span class="toc-section-number">1</span> Preparation</a><ul>
<li><a href="#setting-up-rtweet"><span class="toc-section-number">1.1</span> Setting up <code>rtweet</code></a></li>
<li><a href="#gettimestring-helper-function"><span class="toc-section-number">1.2</span> <code>getTimeString()</code> Helper Function</a></li>
<li><a href="#prepare-filepath-for-.rds-with-here"><span class="toc-section-number">1.3</span> (Prepare filepath for .rds with <code>here()</code>)</a></li>
</ul></li>
<li><a href="#mining-tweets-with-search_tweets"><span class="toc-section-number">2</span> Mining Tweets with <code>search_tweets()</code></a><ul>
<li><a href="#political-science-dvpw18-dvpw2018-and-dvpw"><span class="toc-section-number">2.1</span> Political Science: #dvpw18 / #dvpw2018 (and #dvpw)</a><ul>
<li><a href="#mining"><span class="toc-section-number">2.1.1</span> Mining</a></li>
<li><a href="#wrangling"><span class="toc-section-number">2.1.2</span> Wrangling</a></li>
<li><a href="#treemap-dvpw-dvpw18-dvpw2018"><span class="toc-section-number">2.1.3</span> Treemap: #dvpw / #dvpw18 / #dvpw2018</a></li>
<li><a href="#scatterplot-of-tweets-rts-favs-per-user"><span class="toc-section-number">2.1.4</span> Scatterplot: # of Tweets / RTs / Favs per User</a></li>
<li><a href="#scatterplot-without-dvpw-and-with-labels-for-the-top-20"><span class="toc-section-number">2.1.5</span> Scatterplot without <span class="citation">@dvpw</span> and with labels for the top 20</a></li>
<li><a href="#todo-creating-twitter-lists"><span class="toc-section-number">2.1.6</span> (TODO: Creating Twitter Lists)</a></li>
</ul></li>
<li><a href="#sociology-dgs18-dgs2018"><span class="toc-section-number">2.2</span> Sociology: #dgs18 / #dgs2018</a></li>
<li><a href="#historians-histag18-histag2018-historikertag2018"><span class="toc-section-number">2.3</span> Historians: #histag18 / #histag2018 / #historikertag2018</a></li>
<li><a href="#computer-science-informatik2018"><span class="toc-section-number">2.4</span> Computer Science: #informatik2018</a></li>
<li><a href="#media-studies-gfm2018"><span class="toc-section-number">2.5</span> Media Studies: #gfm2018</a></li>
</ul></li>
<li><a href="#some-comparisons"><span class="toc-section-number">3</span> Some Comparisons</a><ul>
<li><a href="#joint-scatterplot-per-user"><span class="toc-section-number">3.1</span> Joint Scatterplot: per-User</a></li>
<li><a href="#joint-scatterplot-top-20-labelled-wo-dvpw"><span class="toc-section-number">3.2</span> Joint Scatterplot: Top 20 labelled (w/o <span class="citation">@dvpw</span>)</a></li>
<li><a href="#boxplots-overall-distribution-of-activities-by-discipline"><span class="toc-section-number">3.3</span> Boxplots: Overall Distribution of Activities by Discipline</a></li>
</ul></li>
<li><a href="#one-final-table-the-overall-activity-compared-by-numbers"><span class="toc-section-number">4</span> One final table: The overall activity compared by numbers</a></li>
<li><a href="#whats-next"><span class="toc-section-number">5</span> What’s next</a></li>
</ul>
</div>

<div class="figure">
<img src="/img/Twitter_conf/Twitter_conf.png" title="This is what ~~4~~ 5 German academic conferences look like on Twitter" style="width:100.0%" />

</div>
<blockquote>
<p>Update: Since the conferences are over but there’s still some Twitter activity, Tweets posted after 29.09.2018 have been filtered out from the samples.</p>
</blockquote>
<blockquote>
<p>Update 2: The Media Studies conference (#gfm2018) has been included</p>
</blockquote>
<p>As (bad) luck has it, <del>four</del> five big academic societies in Germany somehow decided to hold their respective annual meetings within the same week:</p>
<ul>
<li><p><a href="https://www.dvpw.de/kongresse/dvpw-kongresse/dvpw2018/" target="_blank">Deutsche Vereinigung für Politikwissenschaft / Political Science</a> (#dvpw18, #dvpw2018, #dvpw)</p></li>
<li><p><a href="https://kongress2018.soziologie.de/aktuelles/" target="_blank">Deutsche Gesellschaft für Soziologie / Sociology</a> (#dgs18, #dgs2018)</p></li>
<li><p><a href="https://www.historikertag.de/Muenster2018/" target="_blank">Verband der Historiker und Historikerinnen Deutschlands / History</a> (#histag18 / #histag2018 / #historikertag2018)</p></li>
<li><a href="https://informatik2018.gi.de/" target="_blank">Gesellschaft für Informatik e.V. / Computer Science</a> (#informatik2018)</li>
<li><p><a href="https://gfmedienwissenschaft.de/jahrestagung" target="_blank">Gesellschaft für Medienwissenschaft / Media Studies</a> (#gfm2018)</p></li>
</ul>
<p>Even though Germany is still a bit behind with regards to Twitter, <del>four</del> five conferences = <del>4x</del> 5x the chance to work on your Twitter mining and text wrangling skills ;). Plus, we get some interesting data for the future practice of our NLP / text processing and social network analysis skills…</p>
<p>So let’s just get started with mining. We will use <a href="https://twitter.com/kearneymw" target="_blank">Mike Kearney’s</a> superb <code>rtweet</code> (<a href="https://rtweet.info/" target="_blank">package</a>).</p>
<pre class="r"><code>library(tidyverse)
library(here)
library(rtweet)</code></pre>
<div id="preparation" class="section level1">
<h1><span class="header-section-number">1</span> Preparation</h1>
<div id="setting-up-rtweet" class="section level2">
<h2><span class="header-section-number">1.1</span> Setting up <code>rtweet</code></h2>
<p><strong>Get the Token</strong></p>
<p>Follow the instructions <a href="https://rtweet.info/#api-authorization" target="_blank">here</a>, set up your Twitter app and save your token.</p>
<p>You’ll get something like this (caution: fake credentials)</p>
<pre class="r"><code>appname &lt;- &quot;your_app_name&quot;
key &lt;- &quot;your_consumer_key&quot;
secret &lt;- &quot;your_seceret&quot;</code></pre>
<p><strong>Register your App with R.</strong></p>
<pre class="r"><code>twitter_token &lt;- create_token(
  app = appname,
  consumer_key = key,
  consumer_secret = secret)</code></pre>
<p>And save your token in your environment / home path / working directory.</p>
<p><strong>Save token in Root dir / Home path</strong></p>
<pre class="r"><code>## path of home directory
home_directory &lt;- path.expand(&quot;~/R&quot;)
file_name &lt;- file.path(home_directory, &quot;twitter_token.rds&quot;)

## save token to home directory
saveRDS(twitter_token, file = file_name)
# saveRDS(twitter_token, &quot;twitter_token.rds&quot;) # save locally in wd
twitter_token &lt;- readRDS(str_c(home_directory,&quot;/twitter_token.rds&quot;))</code></pre>
<p><strong>Token check</strong></p>
<pre class="r"><code>identical(twitter_token, get_token())
#&gt; TRUE</code></pre>
</div>
<div id="gettimestring-helper-function" class="section level2">
<h2><span class="header-section-number">1.2</span> <code>getTimeString()</code> Helper Function</h2>
<p>I will use this function for saving time-stamped samples of Tweets</p>
<pre class="r"><code>getTimeString &lt;- function() {
  Sys.time() %&gt;% str_extract_all(regex(&quot;[0-9]&quot;)) %&gt;%
    unlist() %&gt;% glue::glue_collapse()
  }
getTimeString()</code></pre>
<pre><code>## 20180930172836</code></pre>
</div>
<div id="prepare-filepath-for-.rds-with-here" class="section level2">
<h2><span class="header-section-number">1.3</span> (Prepare filepath for .rds with <code>here()</code>)</h2>
<pre class="r"><code># library(here) # https://blogdown-demo.rbind.io/2018/02/27/r-file-paths/
# blogdown-specific work-around for the `data`-folder
data_path &lt;- here(&quot;static&quot;, &quot;data&quot;, &quot;ConferenceTweets&quot;, &quot;/&quot;)
if (!dir.exists(data_path)) dir.create(data_path)
# saveRDS(mtcars, str_c(data_path, &quot;test&quot;, &quot;.rds&quot;)) # test filepath
# readRDS(str_c(data_path, &quot;test&quot;, &quot;.rds&quot;)) # test filepath</code></pre>
</div>
</div>
<div id="mining-tweets-with-search_tweets" class="section level1">
<h1><span class="header-section-number">2</span> Mining Tweets with <code>search_tweets()</code></h1>
<div id="political-science-dvpw18-dvpw2018-and-dvpw" class="section level2">
<h2><span class="header-section-number">2.1</span> Political Science: #dvpw18 / #dvpw2018 (and #dvpw)</h2>
<p>We probably won’t get all the tweets with a single request, so what we are going to do is, to request the Tweets multiple times, consolidate the requests, and finally extract unique Tweets with <code>dplyr::distinct()</code> to get a pretty good sample.</p>
<p>Notice, that we can request <code>recent</code> and <code>mixed</code> samples (<code>popular</code> doesn’t seem to work for me.)</p>
<div id="mining" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Mining</h3>
<p>The workflow suggested here is that you mine a couple of samples (or mine new samples hours or days later), save these sample with time-stamped and therefore unique file names (as <code>.rds</code>), and than consolidate and extract unique tweets with <code>dplyr::distinct()</code></p>
<pre class="r"><code>dvpw_tweets &lt;- search_tweets(q = &quot;#dvpw18 OR #dvpw2018 OR #dvpw&quot;, # explicit QUERY
      include_rts = FALSE,
      # max_id = ,
      n = 5000,
      verbose = TRUE,
      retryonratelimit = TRUE,
      type = &quot;recent&quot;) # mixed recent (popular)

saveRDS(dvpw_tweets, file =
          str_c(data_path,&quot;dvpw_tweets_&quot;, getTimeString(),&quot;.rds&quot;))</code></pre>
</div>
<div id="wrangling" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Wrangling</h3>
<p>Here we’ll get a file list of all <code>dvpw_*.rds</code> files, then <code>map_dfr()</code> them to a <code>data_frame</code> and finally extract unique Tweets with <code>distinct()</code></p>
<pre class="r"><code>## this is just a bit complicated because I&#39;m using an external data folder for blogdown. If you work locally, you can just use:
# map_dfr(dir(path = &quot;.&quot;, &quot;dvpw_&quot;), readRDS)

dvpw_rds &lt;- dir(path = data_path, pattern = &quot;dvpw_&quot;) %&gt;% 
  str_c(data_path, .) %&gt;% 
  map_dfr(readRDS)
dvpw_collection &lt;- dvpw_rds %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;%
  filter(created_at &lt; &quot;2018-09-30&quot;) %&gt;%
  arrange(created_at)</code></pre>
<blockquote>
<p>As you can see from <code>filter(created_at &lt; &quot;2018-09-30&quot;)</code> we will only consider tweets posted before Sunday, 30.09.2018 (for the sake of comparison)</p>
</blockquote>
<p>(How to check the latest/earliest Tweet)</p>
<pre class="r"><code>min(dvpw_collection$status_id) # https://twitter.com/statuses/1041748634486931465
Tweet &lt;- max(dvpw_collection$status_id) 
browseURL(str_c(&quot;https://twitter.com/statuses/&quot;, Tweet))</code></pre>
<p>Time-String for Plotting</p>
<pre class="r"><code>timeString &lt;- str_c(lubridate::hour(Sys.time()), &quot;:&quot;, lubridate::minute(Sys.time()))</code></pre>
</div>
<div id="treemap-dvpw-dvpw18-dvpw2018" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Treemap: #dvpw / #dvpw18 / #dvpw2018</h3>
<p>We’ll need the <code>treemapify</code> <a href="https://github.com/wilkox/treemapify" target="_blank">package</a> for this.</p>
<pre class="r"><code>dvpw_n_tweets &lt;- nrow(dvpw_collection)
dvpw_n_accounts &lt;- length(unique(dvpw_collection$screen_name))
# tidy/dplyr: distinct(screen_name) %&gt;% count()

dvpw_collection %&gt;% 
  group_by(screen_name) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(share = n / sum(n)) %&gt;%
  arrange(desc(n)) %&gt;%
  ggplot(aes(area = share)) +
    treemapify::geom_treemap(aes(fill = log10(n))) +
    treemapify::geom_treemap_text(
      aes(label = paste0(screen_name, &quot; (&quot;, round(share*100,1),&quot;%)&quot;))
      ) +
  scale_fill_viridis_c(direction = -1, option = &quot;C&quot;, begin = 0.8) +
  labs(title = &quot;Twitter-Aktivität zu #dvpw / #dvpw18 / #dvpw2018&quot;,
       subtitle = paste0(&quot;(n = &quot;, dvpw_n_tweets,
                         &quot; Tweets von m = &quot;, dvpw_n_accounts,
                         &quot; Accounts; Stand: 29.09.18, &quot;,
                         &quot;23:59&quot; , &quot; Uhr;&quot;,
                         &quot; by @fubits)&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="scatterplot-of-tweets-rts-favs-per-user" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Scatterplot: # of Tweets / RTs / Favs per User</h3>
<p>For the scatterplot we’ll have to group the single Tweets by user (<code>$screen_name</code>), summarise the counts for Tweets, RTs, and Favs, and assign a “discipline” category for later use.</p>
<pre class="r"><code>dvpw_counts &lt;- dvpw_collection %&gt;%
  group_by(screen_name) %&gt;%
  summarise(Tweets = n(),
            RT = sum(retweet_count),
            Favs = sum(favorite_count)) %&gt;% 
  mutate(discipline = &quot;PolSci&quot;) %&gt;% 
  arrange(desc(Tweets)) # %&gt;% 
  # top_n(n = 50, wt = tweets) </code></pre>
<p>Scatterplot</p>
<pre class="r"><code>ggplot(dvpw_counts, aes(x = Favs, y = RT)) +
  geom_point(aes(size = Tweets, color = screen_name)) +
  ggrepel::geom_text_repel(data = dvpw_counts[1:2,], aes(label = screen_name)) +
  coord_fixed() +
  scale_color_viridis_d() +
  # scale_size_continuous(breaks = c(50, 100, 150, 200, 250, 300)) +
  guides(color = FALSE) +
  theme_minimal() +
  labs(size = &quot;Anzahl Tweets&quot;,
       title = &quot;Twitter-Aktivität zu #dvpw / #dvpw18 / #dvpw2018: Retweets &amp; Favs&quot;,
       subtitle = paste0(&quot;(n = &quot;, dvpw_n_tweets,
                       &quot; Tweets von m = &quot;, dvpw_n_accounts,
                       &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;),
       x = &quot;Anzahl Favourites&quot;,
       y = &quot;Anzahl Retweets&quot;,
       caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-14-1.png" width="1152" /></p>
<p>The official society accounts have been quite busy! Well done, <a href="https://twitter.com/dvpwkongress/status/1040501085067247616" target="_blank">@dvpw/@dvpwkongress</a>, the idea of a Twitter <code>#TeamTakeOver</code> worked out rather well! &lt;- <strong>Note to my future self.</strong>)</p>
</div>
<div id="scatterplot-without-dvpw-and-with-labels-for-the-top-20" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Scatterplot without <span class="citation">@dvpw</span> and with labels for the top 20</h3>
<p>Here we’ll need <code>ggrepel</code> for non-overlapping labeling. Since the official <span class="citation">@dvpw</span> account has been quite an “outlier”, let’s have an undisturbed look at the rest of the field without <span class="citation">@dvpw</span>.</p>
<pre class="r"><code>dvpw_counts %&gt;% filter(screen_name != &quot;dvpw&quot;) %&gt;%
  ggplot(aes(x = Favs, y = RT)) +
    geom_point(aes(size = Tweets, color = screen_name), alpha = 0.5) +
    ggrepel::geom_text_repel(data = dvpw_counts[2:21,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d() +
    scale_x_continuous(breaks = c(0, 50, 100, 150, 200, 250)) +
    guides(color = FALSE) +
    theme_minimal() +
    labs(size = &quot;Anzahl Tweets&quot;,
         title = &quot;Twitter-Aktivität zu #dvpw / #dvpw18 / #dvpw2018: Top 20 Accounts (ohne @dvpw)&quot;,
         subtitle = paste0(&quot;(n = &quot;, sum(filter(dvpw_counts,
                                               screen_name != &quot;dvpw&quot;)$Tweets),
                           &quot; Tweets von m = &quot;, dvpw_n_accounts - 1,
                         &quot; Accounts, ohne @dvpw; Top 20 Label, Stand: 29.09.18, &quot;,
                         &quot;23:59&quot;,&quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-15-1.png" width="1152" /></p>
</div>
<div id="todo-creating-twitter-lists" class="section level3">
<h3><span class="header-section-number">2.1.6</span> (TODO: Creating Twitter Lists)</h3>
<blockquote>
<p>tba, but we could automate creating of user lists from hashtags for conferences… This might be useful for live-curating Twitter handles for better credits to speakers.</p>
</blockquote>
<pre class="r"><code># we need a plain character vector here
dvpw_nicks &lt;- dvpw_collection %&gt;% distinct(screen_name) %&gt;% unlist()
post_list(dvpw_nicks[1:100], name = &quot;dvpw2018&quot;, private = TRUE, destroy = FALSE)
#&gt; Can only add 100 users at a time. Adding users[1:100]...
list_length &lt;- length(dvpw_nicks)
post_list(dvpw_nicks[101:200], slug = &quot;dvpw2018&quot;, private = TRUE, destroy = FALSE)
post_list(dvpw_nicks[200:length(dvpw_nicks)], slug = &quot;dvpw2018&quot;, private = TRUE, destroy = FALSE)

# delete with
# post_list(slug = &quot;dvpw2018&quot;, destroy = TRUE)</code></pre>
</div>
</div>
<div id="sociology-dgs18-dgs2018" class="section level2">
<h2><span class="header-section-number">2.2</span> Sociology: #dgs18 / #dgs2018</h2>
<p>Let’s have a look at how German Sociologists performed on Twitter. Like above, I’ve mined the Tweets multiple times in order to get a good sample.</p>
<p><strong>Mine</strong></p>
<pre class="r"><code>dgs_tweets &lt;- search_tweets(q = &quot;#dgs18 OR #dgs2018&quot;, # explicit QUERY
      include_rts = FALSE,
      # max_id = ,
      n = 5000,
      verbose = TRUE,
      retryonratelimit = TRUE,
      type = &quot;mixed&quot;) # mixed recent (popular)

saveRDS(dgs_tweets,
        file =  str_c(data_path,&quot;dgs_tweets_&quot;, getTimeString(),&quot;.rds&quot;)) </code></pre>
<p><strong>Wrangle</strong></p>
<pre class="r"><code>dgs_rds &lt;- dir(path = data_path, pattern = &quot;dgs_&quot;) %&gt;%
  str_c(data_path, .) %&gt;%
  map_dfr(readRDS)
dgs_collection &lt;- dgs_rds %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;%
  filter(created_at &lt; &quot;2018-09-30&quot;) %&gt;%
  arrange(created_at)</code></pre>
<p><strong>Sociology: Treemap</strong></p>
<pre class="r"><code>dgs_n_tweets &lt;- nrow(dgs_collection)
dgs_n_accounts &lt;- length(unique(dgs_collection$screen_name))

dgs_collection %&gt;%
  group_by(screen_name) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(share = n / sum(n)) %&gt;%
  arrange(desc(n)) %&gt;%
  ggplot(aes(area = share)) +
    treemapify::geom_treemap(aes(fill = log10(n))) +
    treemapify::geom_treemap_text(
      aes(label = paste0(screen_name, &quot; (&quot;, round(share*100,1),&quot;%)&quot;))
      ) +
  scale_fill_viridis_c(direction = -1, option = &quot;C&quot;, begin = 0.8) +
  labs(title = &quot;Twitter-Aktivität zu #dgs18 / #dgs2018&quot;,
       subtitle = str_c(&quot;(n = &quot;, dgs_n_tweets,
                         &quot; Tweets von m = &quot;, dgs_n_accounts,
                         &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;,
                         &quot; by @fubits)&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-19-1.png" width="672" /> That looks rather different from the #dvpw2018 community. Less institutional dominance and actually, many more individual Twitter users (710 active users vs 242 in team PolSci).</p>
<p><strong>Sociology: per-User</strong></p>
<pre class="r"><code>dgs_counts &lt;- dgs_collection %&gt;%
  group_by(screen_name) %&gt;%
  # filter(screen_name != &quot;fubits&quot;) %&gt;% 
  summarise(Tweets = n(),
            RT = sum(retweet_count),
            Favs = sum(favorite_count)) %&gt;%
  mutate(discipline = &quot;Sociology&quot;) %&gt;% 
  arrange(desc(Tweets)) # %&gt;%
  # top_n(n = 50, wt = tweets) </code></pre>
<pre class="r"><code>ggplot(dgs_counts, aes(x = Favs, y = RT)) +
  geom_point(aes(size = Tweets, color = screen_name)) +
  # ggrepel::geom_text_repel(data = counts[1:10,], aes(label = screen_name)) +
  coord_fixed() +
  scale_color_viridis_d() +
  scale_x_continuous(breaks = c(10, 20, 30, 40, 50, 100, 150, 175)) +
  guides(color = FALSE) +
  theme_minimal() +
  labs(size = &quot;Anzahl Tweets&quot;,
       title = &quot;Twitter-Aktivität zu #dgs18 / #dgs2018: Retweets &amp; Favs&quot;,
       subtitle = paste0(&quot;(n = &quot;, dgs_n_tweets,
                       &quot; Tweets von m = &quot;, dgs_n_accounts,
                       &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;),
       x = &quot;Anzahl Favourites&quot;,
       y = &quot;Anzahl Retweets&quot;,
       caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-21-1.png" width="1152" /> Wow, that is quite different, right? Less individual tweets per user, less retweets, but a significantly higher Fav rate. Interesting. Shall we assume that Sociologist are more introvert and maybe have more empathy for others? :)</p>
<p><strong>Sociology: Top 20 labelled</strong></p>
<pre class="r"><code>ggplot(dgs_counts, aes(x = Favs, y = RT)) +
    geom_point(aes(size = Tweets, color = screen_name), alpha = 0.5) +
    ggrepel::geom_text_repel(data = dgs_counts[1:20,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d() +
    scale_x_continuous(breaks = c(10, 20, 30, 40, 50, 100, 150, 175)) +
    guides(color = FALSE) +
    theme_minimal() +
    labs(size = &quot;Anzahl Tweets&quot;,
         title = &quot;Twitter-Aktivität zu #dgs18 / #dgs2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, dgs_n_tweets,
                         &quot; Tweets von m = &quot;, dgs_n_accounts,
                         &quot; Accounts; Top 20 Label, Stand: 29.09.18, &quot;, 
                         &quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-22-1.png" width="1152" /></p>
</div>
<div id="historians-histag18-histag2018-historikertag2018" class="section level2">
<h2><span class="header-section-number">2.3</span> Historians: #histag18 / #histag2018 / #historikertag2018</h2>
<p>Next, let’s look have at the Twitter activity of German History scholars.</p>
<p><strong>Mine</strong></p>
<pre class="r"><code>hist_tweets &lt;- search_tweets(q = &quot;#histag18 OR #histag2018 OR #historikertag2018&quot;, # explicit QUERY
      include_rts = FALSE,
      # max_id = ,
      n = 5000,
      verbose = TRUE,
      retryonratelimit = TRUE,
      type = &quot;mixed&quot;) # mixed recent popular

saveRDS(hist_tweets, file =
          str_c(data_path,&quot;hist_tweets_&quot;,getTimeString(),&quot;.rds&quot;))</code></pre>
<p><strong>Wrangle</strong></p>
<pre class="r"><code>hist_rds &lt;- dir(path = data_path, pattern = &quot;hist_&quot;) %&gt;%
  str_c(data_path, .) %&gt;%
  map_dfr(readRDS)
hist_collection &lt;- hist_rds %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;%
  filter(created_at &lt; &quot;2018-09-30&quot;) %&gt;%
  arrange(created_at)</code></pre>
<p><strong>Historians: Treemap</strong></p>
<pre class="r"><code>hist_n_tweets &lt;- nrow(hist_collection)
hist_n_accounts &lt;- length(unique(hist_collection$screen_name))

hist_collection %&gt;%
  group_by(screen_name) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(share = n / sum(n)) %&gt;%
  arrange(desc(n)) %&gt;%
  ggplot(aes(area = share)) +
    treemapify::geom_treemap(aes(fill = log10(n))) +
    treemapify::geom_treemap_text(
      aes(label = paste0(screen_name, &quot; (&quot;, round(share*100,1),&quot;%)&quot;))
      ) +
  scale_fill_viridis_c(direction = -1, option = &quot;C&quot;, begin = 0.8) +
  labs(title = &quot;Twitter-Aktivität zu #histag18 / #histag2018 / #historikertag2018&quot;,
       subtitle = paste0(&quot;(n = &quot;, hist_n_tweets,
                         &quot; Tweets von m = &quot;, hist_n_accounts,
                         &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;,
                         &quot; by @fubits)&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><strong>Historians: per-User</strong></p>
<pre class="r"><code>hist_counts &lt;- hist_collection %&gt;%
  group_by(screen_name) %&gt;%
  # filter(screen_name != &quot;fubits&quot;) %&gt;% 
  summarise(Tweets = n(),
            RT = sum(retweet_count),
            Favs = sum(favorite_count)) %&gt;%
  mutate(discipline = &quot;History&quot;) %&gt;% 
  arrange(desc(Tweets)) # %&gt;%
  # top_n(n = 50, wt = tweets)  </code></pre>
<pre class="r"><code>ggplot(hist_counts, aes(x = Favs, y = RT)) +
  geom_point(aes(size = Tweets, color = screen_name)) +
  # ggrepel::geom_text_repel(data = counts[1:10,], aes(label = screen_name)) +
  coord_fixed() +
  scale_color_viridis_d() +
  # scale_size_continuous(breaks = c(50, 100, 150, 200, 250, 300)) +
  guides(color = FALSE) +
  theme_minimal() +
  labs(size = &quot;Anzahl Tweets&quot;,
       title = &quot;Twitter-Aktivität zu #histag18 / #histag2018 / #historikertag2018: Retweets &amp; Favs&quot;,
       subtitle = paste0(&quot;(n = &quot;, hist_n_tweets,
                       &quot; Tweets von m = &quot;, hist_n_accounts,
                       &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;),
       x = &quot;Anzahl Favourites&quot;,
       y = &quot;Anzahl Retweets&quot;,
       caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-27-1.png" width="1152" /></p>
<p><strong>Historians: Top 20 labelled</strong></p>
<pre class="r"><code>ggplot(hist_counts, aes(x = Favs, y = RT)) +
    geom_point(aes(size = Tweets, color = screen_name), alpha = 0.5) +
    ggrepel::geom_text_repel(data = hist_counts[1:20,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d() +
    scale_x_continuous(breaks = c(0, 50, 100, 150, 200, 250)) +
    guides(color = FALSE) +
    theme_minimal() +
    labs(size = &quot;Anzahl Tweets&quot;,
         title = &quot;Twitter-Aktivität zu #histag18 / #histag2018 / #historikertag2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, hist_n_tweets,
                         &quot; Tweets von m = &quot;, hist_n_accounts,
                         &quot; Accounts; Top 20 Label, Stand: 29.09.18, &quot;,
                         &quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-28-1.png" width="1152" /></p>
</div>
<div id="computer-science-informatik2018" class="section level2">
<h2><span class="header-section-number">2.4</span> Computer Science: #informatik2018</h2>
<p>(Of course, CS scholars are rather disciplined and stick to one hashtag :) #informatik18 has only 3 Tweets so far, and #informatiktage only 2 users…)</p>
<p><strong>Mine</strong></p>
<pre class="r"><code>inf_tweets &lt;- search_tweets(q = &quot;#informatik2018&quot;, # explicit QUERY
      include_rts = FALSE,
      # max_id = ,
      n = 5000,
      verbose = TRUE,
      retryonratelimit = TRUE,
      type = &quot;recent&quot;) # mixed recent popular

saveRDS(inf_tweets, file =
          str_c(data_path,&quot;inf_tweets_&quot;,getTimeString(),&quot;.rds&quot;))</code></pre>
<p><strong>Wrangle</strong></p>
<pre class="r"><code>inf_rds &lt;- dir(path = data_path, pattern = &quot;inf_&quot;) %&gt;%
  str_c(data_path, .) %&gt;%
  map_dfr(readRDS)
inf_collection &lt;- inf_rds %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;%
  filter(created_at &lt; &quot;2018-09-30&quot;) %&gt;%
  arrange(created_at)</code></pre>
<p><strong>Treemap</strong></p>
<pre class="r"><code>inf_n_tweets &lt;- nrow(inf_collection)
inf_n_accounts &lt;- length(unique(inf_collection$screen_name))

inf_collection %&gt;%
  group_by(screen_name) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(share = n / sum(n)) %&gt;%
  arrange(desc(n)) %&gt;%
  ggplot(aes(area = share)) +
    treemapify::geom_treemap(aes(fill = log10(n))) +
    treemapify::geom_treemap_text(
      aes(label = paste0(screen_name, &quot; (&quot;, round(share*100,1),&quot;%)&quot;))
      ) +
  scale_fill_viridis_c(direction = -1, option = &quot;C&quot;, begin = 0.8) +
  labs(title = &quot;Twitter-Aktivität zu #informatik2018&quot;,
       subtitle = paste0(&quot;(n = &quot;, inf_n_tweets,
                         &quot; Tweets von m = &quot;, inf_n_accounts,
                         &quot; Accounts; Stand: 29.09.18, &quot;, 
                         &quot;23:59&quot; , &quot; Uhr;&quot;,
                         &quot; by @fubits)&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-31-1.png" width="672" /> Hm, that’s quite a few Tweets for a presumably Tech-savie community…</p>
<p><strong>Scatterplot with per-user activity</strong></p>
<pre class="r"><code>inf_counts &lt;- inf_collection %&gt;%
  group_by(screen_name) %&gt;%
  # filter(screen_name != &quot;fubits&quot;) %&gt;% 
  summarise(Tweets = n(),
            RT = sum(retweet_count),
            Favs = sum(favorite_count)) %&gt;% 
  mutate(discipline = &quot;CS&quot;) %&gt;% 
  arrange(desc(Tweets))
  # top_n(n = 50, wt = tweets) %&gt;% </code></pre>
<pre class="r"><code>ggplot(inf_counts, aes(x = Favs, y = RT)) +
  geom_point(aes(size = Tweets, color = screen_name)) +
  # ggrepel::geom_text_repel(data = counts[1:10,], aes(label = screen_name)) +
  coord_fixed() +
  scale_color_viridis_d() +
  # scale_size_continuous(breaks = c(50, 100, 150, 200, 250, 300)) +
  guides(color = FALSE) +
  theme_minimal() +
  labs(size = &quot;Anzahl Tweets&quot;,
       title = &quot;Twitter-Aktivität zu #informatik2018: Retweets &amp; Favs&quot;,
       subtitle = paste0(&quot;(n = &quot;, inf_n_tweets,
                       &quot; Tweets von m = &quot;, inf_n_accounts,
                       &quot; Accounts; Stand: 29.09.18, &quot;, &quot;23:59&quot; , &quot; Uhr;&quot;),
       x = &quot;Anzahl Favourites&quot;,
       y = &quot;Anzahl Retweets&quot;,
       caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-33-1.png" width="1152" /></p>
<blockquote>
<p>So there’s some truth in “I’m a Computer Scientist. We don’t use Twitter”…</p>
</blockquote>
<p><strong>Scatterplot: Top 20 labelled</strong></p>
<pre class="r"><code>ggplot(inf_counts, aes(x = Favs, y = RT)) +
    geom_point(aes(size = Tweets, color = screen_name), alpha = 0.5) +
    ggrepel::geom_text_repel(data = inf_counts[1:20,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d() +
    scale_x_continuous(breaks = c(0, 20, 40, 60, 80)) +
    guides(color = FALSE) +
    theme_minimal() +
    labs(size = &quot;Anzahl Tweets&quot;,
         title = &quot;Twitter-Aktivität zu #informatik2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, inf_n_tweets,
                         &quot; Tweets von m = &quot;, inf_n_accounts,
                         &quot; Accounts; Top 20 Label, Stand: 29.09.18, &quot;,
                         &quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-34-1.png" width="1152" /></p>
</div>
<div id="media-studies-gfm2018" class="section level2">
<h2><span class="header-section-number">2.5</span> Media Studies: #gfm2018</h2>
<blockquote>
<p>As I have <a href="https://twitter.com/__evamaria__/status/1046389871001128960" target="_blank">just been informed</a> on Twitter, the German Society for Media Studies also had their annual meeting this week. That’s like some weird multidisciplinary but still strictly unidisciplinary academic conspiracy…</p>
</blockquote>
<p>However, let’s have a look at #gfm2018, too!</p>
<p><strong>Mine</strong></p>
<pre class="r"><code>gfm_tweets &lt;- search_tweets(q = &quot;#gfm2018&quot;, # explicit QUERY
      include_rts = FALSE,
      # max_id = ,
      n = 5000,
      verbose = TRUE,
      retryonratelimit = TRUE,
      type = &quot;recent&quot;) # mixed recent popular

saveRDS(gfm_tweets, file =
          str_c(data_path,&quot;gfm_tweets_&quot;,getTimeString(),&quot;.rds&quot;))</code></pre>
<p><strong>Wrangle</strong></p>
<pre class="r"><code>gfm_rds &lt;- dir(path = data_path, pattern = &quot;gfm_&quot;) %&gt;%
  str_c(data_path, .) %&gt;%
  map_dfr(readRDS)
gfm_collection &lt;- gfm_rds %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;%
  filter(created_at &lt; &quot;2018-09-30&quot;) %&gt;%
  arrange(created_at)</code></pre>
<p><strong>Treemap</strong></p>
<pre class="r"><code>gfm_n_tweets &lt;- nrow(gfm_collection)
gfm_n_accounts &lt;- length(unique(gfm_collection$screen_name))

gfm_collection %&gt;%
  group_by(screen_name) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(share = n / sum(n)) %&gt;%
  arrange(desc(n)) %&gt;%
  ggplot(aes(area = share)) +
    treemapify::geom_treemap(aes(fill = log10(n))) +
    treemapify::geom_treemap_text(
      aes(label = paste0(screen_name, &quot; (&quot;, round(share*100,1),&quot;%)&quot;))
      ) +
  scale_fill_viridis_c(direction = -1, option = &quot;C&quot;, begin = 0.8) +
  labs(title = &quot;Twitter-Aktivität zu #gfm2018&quot;,
       subtitle = paste0(&quot;(n = &quot;, gfm_n_tweets,
                         &quot; Tweets von m = &quot;, gfm_n_accounts,
                         &quot; Accounts; Stand: 29.09.18, &quot;, 
                         &quot;23:59&quot; , &quot; Uhr;&quot;,
                         &quot; by @fubits)&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<blockquote>
<p>Let’s treat this as preliminary. I’ve just mined the Tweets for the first time, so a couple more samples might another couple of Tweets. Don’t expect the numbers to double, though!</p>
</blockquote>
<p><strong>Scatterplot with per-user activity</strong></p>
<pre class="r"><code>gfm_counts &lt;- gfm_collection %&gt;%
  group_by(screen_name) %&gt;%
  # filter(screen_name != &quot;fubits&quot;) %&gt;% 
  summarise(Tweets = n(),
            RT = sum(retweet_count),
            Favs = sum(favorite_count)) %&gt;% 
  mutate(discipline = &quot;MediaStudies&quot;) %&gt;% 
  arrange(desc(Tweets))
  # top_n(n = 50, wt = tweets) %&gt;% </code></pre>
<p>Since there’s not too much activity for #gfm2018, we can jump to the labelled scatterplot.</p>
<p><strong>Scatterplot: Top 20 labelled</strong></p>
<pre class="r"><code>ggplot(gfm_counts, aes(x = Favs, y = RT)) +
    geom_point(aes(size = Tweets, color = screen_name), alpha = 0.5) +
    ggrepel::geom_text_repel(data = gfm_counts[1:20,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d() +
    scale_x_continuous(breaks = c(0, 10, 20, 40, 60, 80, 100, 110)) +
    guides(color = FALSE) +
    theme_minimal() +
    labs(size = &quot;Anzahl Tweets&quot;,
         title = &quot;Twitter-Aktivität zu #gfm2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, gfm_n_tweets,
                         &quot; Tweets von m = &quot;, gfm_n_accounts,
                         &quot; Accounts; Top 20 Label, Stand: 29.09.18, &quot;,
                         &quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-39-1.png" width="1152" /></p>
</div>
</div>
<div id="some-comparisons" class="section level1">
<h1><span class="header-section-number">3</span> Some Comparisons</h1>
<p>First, we will need to bind the four tibbles together. First, let’s get the total numbers of unique Tweets and unique users:</p>
<pre class="r"><code>all_cons &lt;- bind_rows(dvpw_collection, dgs_collection, hist_collection, inf_collection, gfm_collection)
all_n_accounts &lt;- all_cons %&gt;% distinct(screen_name) %&gt;% nrow()
all_n_tweets &lt;- all_cons %&gt;% distinct(status_id) %&gt;% nrow()</code></pre>
<p>So, this week, 1320 German academic Twitter accounts have been active at four conferences in total, producing 4943 individual Tweets. Actually, that’s quite impressive!</p>
<p>Now we can bind the aggregated *_counts.</p>
<pre class="r"><code>all_cons_per_user &lt;- bind_rows(dvpw_counts, dgs_counts, hist_counts, inf_counts, gfm_counts) %&gt;%
  group_by(screen_name) %&gt;% 
  distinct(screen_name, .keep_all = TRUE) %&gt;% 
  mutate(avg_output = (Tweets + RT + Favs)/3) %&gt;% 
  arrange(desc(avg_output)) #&gt; 1262
# all_cons_per_user %&gt;% distinct(screen_name) %&gt;% count() #&gt; 1262
all_cons_per_user %&gt;% head(20)</code></pre>
<pre><code>## # A tibble: 20 x 6
## # Groups:   screen_name [20]
##    screen_name     Tweets    RT  Favs discipline avg_output
##    &lt;chr&gt;            &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;
##  1 dvpw               368   423   522 PolSci          438. 
##  2 dvpwkongress       135   173   368 PolSci          225. 
##  3 thothiel            44    98   272 PolSci          138  
##  4 digigw              34   121   225 History         127. 
##  5 Mareike2405         24    73   275 History         124  
##  6 ronpatz             58    60   208 PolSci          109. 
##  7 elvira_rosert       41    41   179 PolSci           87  
##  8 PortalLISA          20    78   163 History          87  
##  9 moritz_hoffmann      9    24   226 History          86.3
## 10 historikertag       13    43   201 History          85.7
## 11 SassanGholiagha     86    31   138 PolSci           85  
## 12 janinefunke         12    29   213 History          84.7
## 13 LordElend           26    32   184 Sociology        80.7
## 14 jakobfrohmann       41    60   129 History          76.7
## 15 juergenzimmerer      7    51   171 History          76.3
## 16 DrMichaelHein       21    30   176 PolSci           75.7
## 17 RichterHedwig        7     8   203 History          72.7
## 18 wahlforschung       35    35   144 PolSci           71.3
## 19 PetraGuasti         84    28    92 PolSci           68  
## 20 daniellambach       33    38   133 PolSci           68</code></pre>
<div id="joint-scatterplot-per-user" class="section level2">
<h2><span class="header-section-number">3.1</span> Joint Scatterplot: per-User</h2>
<p>Let’s have a look at this week’s German academic Twitter crowd as a whole:</p>
<pre class="r"><code>ggplot(all_cons_per_user, aes(x = Favs, y = RT, color = discipline)) +
    geom_point(aes(size = Tweets), alpha = 0.5) +
    ggrepel::geom_text_repel(data = all_cons_per_user[1,],
                             aes(label = screen_name)) +
    coord_fixed() +
    scale_color_viridis_d(option = &quot;D&quot;) +
    scale_x_continuous(breaks = c(0, 100, 200, 300, 400)) +
    theme_minimal() +
    guides(colour = guide_legend(override.aes = list(size = 5, stroke = 1.5))) +
    labs(size = &quot;Anzahl Tweets&quot;,
         color = &quot;Disziplin&quot;,
         title = &quot;Twitter-Aktivität zu Twitter-Aktivität zu #dvpw*18, #dgs*18, #hist*18, #informatik2018 und #gfm2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, all_n_tweets,
                         &quot; Tweets von m = &quot;, all_n_accounts,
                         &quot; Accounts; Top 20 Label, Stand: 29.09.18, &quot;,
                         &quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-42-1.png" width="1152" /></p>
</div>
<div id="joint-scatterplot-top-20-labelled-wo-dvpw" class="section level2">
<h2><span class="header-section-number">3.2</span> Joint Scatterplot: Top 20 labelled (w/o <span class="citation">@dvpw</span>)</h2>
<pre class="r"><code>all_cons_per_user %&gt;% 
  filter(screen_name != &quot;dvpw&quot;) %&gt;%
  ggplot(aes(x = Favs, y = RT, color = discipline)) +
    geom_point(aes(size = Tweets), alpha = 0.5) +
    ggrepel::geom_text_repel(data = all_cons_per_user[2:21,],
                             aes(label = screen_name), alpha = 1) +
    coord_fixed() +
    scale_color_viridis_d(option = &quot;D&quot;) +
    scale_x_continuous(breaks = c(0, 50, 100, 150, 200, 250)) +
    theme_minimal() +
    guides(colour = guide_legend(override.aes = list(size = 5, stroke = 1.5))) +
    labs(size = &quot;Anzahl Tweets&quot;,
         color = &quot;Disziplin&quot;,
         title = &quot;Twitter-Aktivität zu #dvpw*18, #dgs*18, #hist*18, #informatik2018 und #gfm2018: Top 20 Accounts&quot;,
         subtitle = paste0(&quot;(n = &quot;, all_n_tweets,
                         &quot; Tweets von m = &quot;, all_n_accounts-1,
                         &quot; Accounts (ohne @dvpw); Top 20 Label, Stand: 29.09.18, &quot;,&quot;23:59&quot;, &quot; Uhr)&quot;),
         x = &quot;Anzahl Favourites&quot;,
         y = &quot;Anzahl Retweets&quot;,
         caption = &quot;@fubits&quot;)</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-43-1.png" width="1152" /> That’s what one week of academic twitter activity in Germany looks like, Duh!</p>
</div>
<div id="boxplots-overall-distribution-of-activities-by-discipline" class="section level2">
<h2><span class="header-section-number">3.3</span> Boxplots: Overall Distribution of Activities by Discipline</h2>
<p>For Boxplot, we need to wrangle the data into long (~tidy) form:</p>
<pre class="r"><code>dvpw_box &lt;- dvpw_counts %&gt;% 
  gather(&quot;Metric&quot;, &quot;Total&quot;, 2:4) #%&gt;%
  # mutate(Discipline = &quot;PolSci&quot;)
dvpw_box %&gt;% filter(screen_name == &quot;dvpw&quot;)</code></pre>
<pre><code>## # A tibble: 3 x 4
##   screen_name discipline Metric Total
##   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;  &lt;int&gt;
## 1 dvpw        PolSci     Tweets   368
## 2 dvpw        PolSci     RT       423
## 3 dvpw        PolSci     Favs     522</code></pre>
<pre class="r"><code>dgs_box &lt;- dgs_counts %&gt;% 
  gather(&quot;Metric&quot;, &quot;Total&quot;, 2:4) # %&gt;%
  # mutate(Discipline = &quot;Socio&quot;)</code></pre>
<pre class="r"><code>hist_box &lt;- hist_counts %&gt;% 
  gather(&quot;Metric&quot;, &quot;Total&quot;, 2:4) # %&gt;%
  # mutate(Discipline = &quot;History&quot;)</code></pre>
<pre class="r"><code>inf_box &lt;- inf_counts %&gt;% 
  gather(&quot;Metric&quot;, &quot;Total&quot;, 2:4) # %&gt;%
  # mutate(Discipline = &quot;CS&quot;)</code></pre>
<pre class="r"><code>gfm_box &lt;- gfm_counts %&gt;% 
  gather(&quot;Metric&quot;, &quot;Total&quot;, 2:4) # %&gt;%
  # mutate(Discipline = &quot;CS&quot;)</code></pre>
<pre class="r"><code>bind_rows(dvpw_box, dgs_box, hist_box, inf_box, gfm_box) %&gt;% 
  ggplot() +
  geom_boxplot(aes(fct_inorder(Metric), Total)) +
  scale_x_discrete() +
  scale_fill_viridis_d() +
  facet_wrap(vars(discipline))</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r"><code>bind_rows(dvpw_box, dgs_box, hist_box, inf_box, gfm_box) %&gt;% 
  ggplot() +
  geom_violin(aes(fct_inorder(Metric), Total, fill = Metric)) +
  scale_x_discrete() +
  scale_fill_viridis_d() +
  facet_wrap(vars(discipline)) +
  labs(x = &quot;Distribution of Tweets / RT / Favs per User&quot;,
       legend = NULL) +
  theme_light()</code></pre>
<p><img src="/post/2018-09-28-r-academic-conference-twitter-pt-1-mining-dvpw18-dgs18-hist18-et-al_files/figure-html/unnamed-chunk-50-1.png" width="672" /> Mmmh, I think I should try those <a href="https://github.com/eclarke/ggbeeswarm" target="_blank">beeswarm-plots</a> soon-ish here…</p>
</div>
</div>
<div id="one-final-table-the-overall-activity-compared-by-numbers" class="section level1">
<h1><span class="header-section-number">4</span> One final table: The overall activity compared by numbers</h1>
<p>What, if we simply compare the disciplines’ Twitter performance by simple totals?</p>
<pre class="r"><code>bind_rows(dvpw_counts, dgs_counts, hist_counts, inf_counts, gfm_counts) %&gt;%
  group_by(discipline) %&gt;% 
  summarise(Users = n(), Tweets = sum(Tweets),
            RT = sum(RT), Fav = sum(Favs)) %&gt;% 
  arrange(desc(Users))</code></pre>
<pre><code>## # A tibble: 5 x 5
##   discipline   Users Tweets    RT   Fav
##   &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 Sociology      704   1658   615  8477
## 2 History        302   1086  1679  6750
## 3 PolSci         238   1691  1680  5341
## 4 CS              97    302   397  1039
## 5 MediaStudies    43    130   157   621</code></pre>
<p>And we if we average out Tweets+RTs+Favs per User?</p>
<pre class="r"><code>bind_rows(dvpw_counts, dgs_counts, hist_counts, inf_counts, gfm_counts) %&gt;%
  group_by(discipline) %&gt;% 
  summarise(Users = n(), Tweets = sum(Tweets),
            RT = sum(RT), Fav = sum(Favs)) %&gt;% 
  mutate(avg_output = (Tweets + RT + Fav)/Users) %&gt;% 
  arrange(desc(avg_output))</code></pre>
<pre><code>## # A tibble: 5 x 6
##   discipline   Users Tweets    RT   Fav avg_output
##   &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;
## 1 PolSci         238   1691  1680  5341       36.6
## 2 History        302   1086  1679  6750       31.5
## 3 MediaStudies    43    130   157   621       21.1
## 4 CS              97    302   397  1039       17.9
## 5 Sociology      704   1658   615  8477       15.3</code></pre>
<p>And now let’s have look without the <code>#TeamTakeOver</code> coup by <code>@dvpw</code>:</p>
<pre class="r"><code>bind_rows(dvpw_counts, dgs_counts, hist_counts, inf_counts, gfm_counts) %&gt;%
  filter(screen_name != &quot;dvpw&quot;) %&gt;% 
  group_by(discipline) %&gt;% 
  summarise(Users = n(), Tweets = sum(Tweets),
            RT = sum(RT), Fav = sum(Favs)) %&gt;% 
  mutate(avg_output = (Tweets + RT + Fav)/Users) %&gt;% 
  arrange(desc(avg_output))</code></pre>
<pre><code>## # A tibble: 5 x 6
##   discipline   Users Tweets    RT   Fav avg_output
##   &lt;chr&gt;        &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;
## 1 History        302   1086  1679  6750       31.5
## 2 PolSci         237   1323  1257  4819       31.2
## 3 MediaStudies    43    130   157   621       21.1
## 4 CS              97    302   397  1039       17.9
## 5 Sociology      704   1658   615  8477       15.3</code></pre>
<p>I guess it is fair to conclude that well organised Twitter takeovers by conference participants have quite an effect on the visibility of a conference.</p>
<p>Further interpretation is up to you :)</p>
</div>
<div id="whats-next" class="section level1">
<h1><span class="header-section-number">5</span> What’s next</h1>
<p>One hint:</p>
<pre class="r"><code>library(quanteda)
library(tidygraph)</code></pre>
<p>But that is for another post…</p>
</div>
